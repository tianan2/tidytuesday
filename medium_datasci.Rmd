---
title: "Untitled"
author: "Jaehwan Lim"
date: "January 15, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(stringr)

medium_datasci <- read_csv("https://github.com/rfordatascience/tidytuesday/blob/master/data/2018/2018-12-04/medium_datasci.csv?raw=true") %>% 
  select(-x1)

```

```{r}
medium_datasci %>% 
  summarize_at(vars(starts_with("tag_")), sum)

medium_gathered <- medium_datasci %>% 
  ## another way to code the third arguement - starts_with("tag_")
  gather(tag, frequency, c(tag_ai:tag_machine_learning)) %>% 
  ## novel approach to clean the string - str_remove
  mutate(tag = str_remove(tag, "tag_")) %>% 
  ## another step that I haven't figured out
  filter(frequency == 1)
  
medium_gathered %>% 
  count(tag, sort = TRUE)

medium_gathered %>% 
  group_by(tag) %>% 
  summarize(median_claps = median(claps)) %>% 
  arrange(desc(median_claps))

## why do we use median instead of mean?
medium_datasci %>% 
  ggplot(aes(claps)) + 
  geom_histogram() + 
  scale_x_log10()

medium_datasci %>% 
  mutate(reading_time = pmin(10, reading_time)) %>% 
  ggplot(aes(reading_time)) + 
  geom_histogram() + 
  scale_x_continuous(breaks = seq(2, 10, 2), 
                     labels = c(seq(2, 8, 2), "10+"))


```
## Text Mining

```{r}
library(tidytext)

medium_datasci %>% 
  select(title, subtitle, year, reading_time, claps) %>% 
  unnest_tokens(word, title) %>% 
  anti_join(stop_words, by = "word") %>% 
  count(word, sort = T)
  
  
  

```

