---
title: "Untitled"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(schrute)

theme_set(theme_light())

office_transcript <- as_tibble(theoffice) %>% mutate(season = as.integer(season), 
                                                     episode = as.integer(episode)) %>% 
  mutate(character = str_remove_all(character, '"'))
  

office_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv')
```

```{r}
office_ratings %>% 
  group_by(season) %>% 
  summarize(avg_rating = mean(imdb_rating)) %>% 
  ggplot(aes(season, avg_rating)) + 
  geom_line() +
  scale_x_continuous(breaks = 1:9)

office_ratings %>% 
  mutate(title = fct_inorder(title), 
         episode_number = row_number()) %>% 
  ggplot(aes(episode_number, imdb_rating)) +
  geom_line() +
  geom_smooth() +
  geom_point(aes(color = as.factor(season), size = total_votes)) +
  geom_text(aes(label = title), check_overlap = TRUE, hjust = 1) +
  expand_limits(x = -10) +
  theme(legend.position = "none", 
        panel.grid.major.x = element_blank()) +
  labs(x = "Episode number", 
       y = "IMDB rating", 
       title = "Popularity of The Office episodes over time", 
       subtitle = "Color represents season, size represents the number of votes")
  
```

```{r}
office_ratings %>% 
  arrange(desc(imdb_rating)) %>% 
  mutate(title = paste0(season, ":", episode, " ", title), 
         title = fct_reorder(title, imdb_rating)) %>% 
  head(20) %>% 
  ggplot(aes(title, imdb_rating, color = as.factor(season), size = total_votes)) +
  geom_point() +
  coord_flip()
```

```{r}
library(tidytext)

transcript_words <- office_transcript %>% 
  group_by(character) %>%
  filter(n() >= 100, 
         n_distinct(episode_name) > 2) %>% 
  ungroup() %>% 
  select(-text_w_direction) %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = "word") %>% 
  filter(!word %in% black_list, 
         !character %in% blacklist_character) 

black_list <- c("yeah", "hey", "uh", "gonna", "um")
blacklist_character <- c("Group", "Everyone", "All", "Guy", "Both", "Girl")

```

```{r}
character_tf_idf <- transcript_words %>% 
  add_count(word) %>% 
  filter(n > 20) %>% 
  count(word, character) %>% 
  bind_tf_idf(word, character, n) %>% 
  arrange(desc(tf_idf))

character_tf_idf %>% 
  filter(character %in% c("Dwight", "Jim", "Michael", "Darryl")) %>% 
  group_by(character) %>% 
  top_n(10, tf_idf) %>% 
  ungroup() %>% 
  mutate(word = reorder_within(word, tf_idf, character)) %>% 
  ggplot(aes(word, tf_idf)) +
  geom_col() +
  scale_x_reordered() +
  coord_flip() +
  facet_wrap(~ character, scales = "free")
```

### Machine learning model

What affects popularity of an episode?

* Season/time
* Director
* Writer
* Lines per character

```{r}
# Joining datasets together turns out to be harder than initially thought
office_transcript %>%
  count(episode_name, character) %>% 
  distinct(episode_name) %>% 
  anti_join(office_ratings, by = c("episode_name" = "title"))

# On what variable the datasets can be joined better?
office_transcript %>% 
  count(season, episode, episode_name) %>% 
  filter(season == 4)

office_ratings %>% 
  count(season, episode, title) %>% 
  filter(season == 4)


# Try again joining daasets
office_transcript <- office_transcript %>% 
  mutate(name = str_to_lower(str_remove_all(episode_name, "\\.| \\(Part.*")))

office_ratings <- office_ratings %>% 
  mutate(name = str_to_lower(str_remove_all(title, "\\.| \\(Part.*|\\: Part.*")))

office_transcript %>% 
  distinct(name) %>% 
  anti_join(office_ratings, by = "name")

# still we have ten names that don't line up

office_ratings %>% 
  distinct(name) %>% 
  anti_join(office_transcript, by = "name")

# now we only have 7; we've got very close!
```

```{r}
ratings_summarized <- office_ratings %>% 
  group_by(name) %>% 
  summarize(imdb_rating = mean(imdb_rating)) 

character_lines_ratings <- office_transcript %>% 
  filter(!character %in% blacklist_character) %>% 
  count(name, character) %>% 
  group_by(character) %>% 
  filter(sum(n) >= 50, 
         n() >= 5) %>% 
  inner_join(ratings_summarized, by = "name") 

character_lines_ratings %>% 
  summarize(avg_rating = mean(imdb_rating), 
            nb_episode = n()) %>% 
  arrange(desc(avg_rating))
```

## Try to do a machine learning model to predict the ratings based on the number of lines per a parcular character

```{r}
director_writer_features <- office_transcript %>% 
  distinct(name, director, writer) %>% 
  gather(type, value, director, writer) %>%
  separate_rows(value, sep = ";") %>% 
  unite(feature, type, value, sep = ": ") %>% 
  # count(feature, sort = TRUE) 
  group_by(feature) %>% 
  filter(n() > 3) %>% 
  mutate(value = 1) %>% 
  ungroup()
  
character_line_features <- character_lines_ratings %>% 
  ungroup() %>% 
  transmute(name, feature = character, value = log2(n))

season_features <- office_ratings %>% 
  distinct(season, name) %>% 
  transmute(name, feature = paste("season:", season), value = 1)

features <- bind_rows(director_writer_features, 
                      character_line_features, 
                      season_features) %>% 
  semi_join(office_ratings, by = "name") %>% 
  semi_join(office_transcript, by = "name")
```

```{r}
episode_feature_matrix <- features %>% 
  cast_sparse(name, feature, value) 

dim(episode_feature_matrix)

ratings <- ratings_summarized$imdb_rating[match(rownames(episode_feature_matrix), ratings_summarized$name)]

library(glmnet)
library(broom)

mod <- cv.glmnet(episode_feature_matrix, ratings)

plot(mod)

# this is showing if I just did linear regression, how well would it do and I started adding a lamda penalty term that causes the coefficents to be smaller or to be regularized, to not allowe large coefficients how much better the prediction will get 

tidy(mod$glmnet.fit) %>% 
  filter(lambda == mod$lambda.min, 
         term != "(Intercept)") %>% 
  mutate(term = fct_reorder(term, estimate)) %>% 
  ggplot(aes(term, estimate, fill = estimate > 0)) +
  geom_col() +
  coord_flip() +
  labs(y = "Estimated effects on the rating of an episode") +
  theme(legend.position = "none")
```

